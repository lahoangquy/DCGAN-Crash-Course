{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN or Deep Convolutional GAN, is a generative adversarial network architecture. It uses a couple of guidelines. In particular:\n",
        "\n",
        "\n",
        "\n",
        "*   Replacing any pooling layers with the strided convolutions (discriminator) and fractional-strided convolutions (generators)\n",
        "\n",
        "*   Using bathnorm in both generator and discriminator\n",
        "*   Removing fully connected hiiden layers for deeper architecture\n",
        "\n",
        "\n",
        "*   Using ReLU activation in generator for all lyers except for the output which uses tanh\n",
        "\n",
        "\n",
        "*   Using LeakyReLu activation in the discriminator for all layers\n",
        "\n",
        "this is the source : https://paperswithcode.com/method/dcgan#:~:text=DCGAN%2C%20or%20Deep%20Convolutional%20GAN,the%20generator%20and%20the%20discriminator.\n",
        "\n"
      ],
      "metadata": {
        "id": "BlALnp-f4PfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, Flatten,Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Conv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lbmj1iit5_yM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dims = 28\n",
        "img_chn1 = 1\n",
        "ltnt_dim = 100"
      ],
      "metadata": {
        "id": "oqAL1qDD6jax"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f9yuqX6uSB",
        "outputId": "494c6290-bc12-4977-c2e9-41e3c36ef868"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "-P4Lm_rB632t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to make sure that each image has a third dimension\n",
        "x_train = np.expand_dims(x_train, axis=3) # 28x28x1\n",
        "x_test = np.expand_dims(x_test, axis=3)"
      ],
      "metadata": {
        "id": "6oXujQw77Gte"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_4YlqtT7azs",
        "outputId": "dafefb77-c126-49b8-9268-58ff069551f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_test shape:  (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the generator network\n",
        "inpt_noise = Input(shape=(ltnt_dim))\n",
        "\n",
        "g11 = Dense(7*7*256, activation='relu')(inpt_noise)\n",
        "g12 = BatchNormalization()(g11)\n",
        "g13 = Reshape((7,7,256))(g12)\n",
        "g14= Conv2DTranspose(128, (5,5), strides=(1,1),padding='same', activation='relu')(g13)\n",
        "g15 = BatchNormalization()(g14)\n",
        "g16= Conv2DTranspose(64, (5,5), strides=(2,2),padding='same', activation='relu')(g15)\n",
        "g17 = BatchNormalization()(g16)\n",
        "g18= Conv2DTranspose(1, (5,5), strides=(2,2),padding='same', activation='sigmoid')(g17)\n",
        "generator = Model(inpt_noise, g18)\n",
        "gnrtr_img = generator(inpt_noise)\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_eTffBJ8rPe",
        "outputId": "4671e4a1-ac61-4ed5-9ecc-bd97bb0483e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12544)             1266944   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12544)            50176     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819328    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1601      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,343,681\n",
            "Trainable params: 2,318,209\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the  discriminator.\n",
        "inpt_img = Input(shape=(img_dims,img_dims, img_chn1 ))\n",
        "d11 = Conv2D(64,(5,5), strides=(2,2), padding='same', activation='relu')(inpt_img)\n",
        "d12= Dropout(0.3)(d11)\n",
        "\n",
        "d13 = Conv2D(128,(5,5), strides=(2,2), padding='same', activation='relu')(d12)\n",
        "d14= Dropout(0.3)(d13)\n",
        "\n",
        "d15 = Flatten()(d14)\n",
        "d16= Dense(1,activation='sigmoid')(d15)\n",
        "critic = Model(inpt_img, d16)\n",
        "validity = critic(gnrtr_img)\n",
        "critic.summary() # critic = discriminator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu6V9fKa_Hm-",
        "outputId": "8aabc521-1f78-4859-9a00-611573b9b6a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will put things together\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "# Compiling the discriminator\n",
        "critic.compile(loss='binary_crossentropy', optimizer=optimizer, \n",
        "               metrics=['accuracy'])\n",
        "# We will freeze the discriminator \n",
        "critic.trainable = False\n",
        "gen_critic = Model(inpt_noise, validity) # full model\n",
        "gen_critic.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "# Creating some trainable parameters\n",
        "epochs = 12001\n",
        "batch_size = 128 # small batches is highly recommended\n",
        "sample_interval = 200 # generatoing samples"
      ],
      "metadata": {
        "id": "OzpuXtrCB8VM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FXjYwaLVDbyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}