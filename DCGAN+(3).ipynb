{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN or Deep Convolutional GAN, is a generative adversarial network architecture. It uses a couple of guidelines. In particular:\n",
        "\n",
        "\n",
        "\n",
        "*   Replacing any pooling layers with the strided convolutions (discriminator) and fractional-strided convolutions (generators)\n",
        "\n",
        "*   Using bathnorm in both generator and discriminator\n",
        "*   Removing fully connected hiiden layers for deeper architecture\n",
        "\n",
        "\n",
        "*   Using ReLU activation in generator for all lyers except for the output which uses tanh\n",
        "\n",
        "\n",
        "*   Using LeakyReLu activation in the discriminator for all layers\n",
        "\n",
        "this is the source : https://paperswithcode.com/method/dcgan#:~:text=DCGAN%2C%20or%20Deep%20Convolutional%20GAN,the%20generator%20and%20the%20discriminator.\n",
        "\n"
      ],
      "metadata": {
        "id": "BlALnp-f4PfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, Flatten,Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Conv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lbmj1iit5_yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dims = 28\n",
        "img_chn1 = 1\n",
        "ltnt_dim = 100"
      ],
      "metadata": {
        "id": "oqAL1qDD6jax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f9yuqX6uSB",
        "outputId": "1969abec-a951-4d51-f556-e3469e3f99f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_dims = 28\n",
        "img_chn1 = 1\n",
        "ltnt_dim=100\n",
        "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "x_train = np.expand_dims(x_train,axis=3)\n",
        "x_test = np.expand_dims(x_test,axis=3)"
      ],
      "metadata": {
        "id": "R_pIXP_J8EZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_4YlqtT7azs",
        "outputId": "fe4dd9a6-fe50-4f07-c9bb-1ae2e9c0588b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_test shape:  (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will build the generator convolutional neural network\n",
        "inpt_noise = Input(shape=(ltnt_dim))\n",
        "g11 = Dense(7*7*256, activation='relu')(inpt_noise)\n",
        "g12 = BatchNormalization()(g11)\n",
        "g13 = Reshape((7,7,256))(g12)\n",
        "g14= Conv2DTranspose(128, (5,5), strides=(1,1),padding='same', activation='relu')(g13)\n",
        "g15 = BatchNormalization()(g14)\n",
        "g16= Conv2DTranspose(64, (5,5), strides=(2,2),padding='same', activation='relu')(g15)\n",
        "g17 = BatchNormalization()(g16)\n",
        "g18= Conv2DTranspose(1, (5,5), strides=(2,2),padding='same', activation='sigmoid')(g17)\n",
        "generator = Model(inpt_noise, g18)\n",
        "gnrtr_img = generator(inpt_noise)\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_eTffBJ8rPe",
        "outputId": "60a9bd4a-14bd-457e-ad74-0eb60db27c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12544)             1266944   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819328    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1601      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,343,681\n",
            "Trainable params: 2,318,209\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "erIPIe9O8Ckm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the critic convolutional network\n",
        "inpt_img = Input(shape=(img_dims,img_dims, img_chn1 ))\n",
        "d11 = Conv2D(64,(5,5), strides=(2,2), padding='same', activation='relu')(inpt_img)\n",
        "d12= Dropout(0.3)(d11)\n",
        "\n",
        "d13 = Conv2D(128,(5,5), strides=(2,2), padding='same', activation='relu')(d12)\n",
        "d14= Dropout(0.3)(d13)\n",
        "\n",
        "d15 = Flatten()(d14)\n",
        "d16= Dense(1,activation='sigmoid')(d15)\n",
        "critic = Model(inpt_img, d16)\n",
        "validity = critic(gnrtr_img)\n",
        "critic.summary()\n",
        "critic.summary() # critic = discriminator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu6V9fKa_Hm-",
        "outputId": "2c5d880c-0cac-48c7-ba00-ce14bed928a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "critic.compile(loss='binary_crossentropy', optimizer=optimizer, \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "critic.trainable = False\n",
        "\n",
        "gen_crt = Model(inpt_noise, validity)\n",
        "gen_crt.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "epochs = 12001\n",
        "batch_size=64\n",
        "sample_interval=400"
      ],
      "metadata": {
        "id": "OzpuXtrCB8VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "samp_imgs = {}\n",
        "closs = []\n",
        "gloss = []\n",
        "cacc = []\n",
        "for epoch in range(epochs):\n",
        "  idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "  imgs = x_train[idx]\n",
        "\n",
        "  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "  c_loss_real = critic.train_on_batch(imgs, valid)\n",
        "  c_loss_fake = critic.train_on_batch(gen_imgs, fake)\n",
        "  c_loss = 0.5 * np.add(c_loss_real, c_loss_fake)\n",
        "\n",
        "  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n",
        "  g_loss = gen_crt.train_on_batch(noise, valid)\n",
        "  \n",
        "  closs.append(c_loss[0])\n",
        "  cacc.append(c_loss[1])\n",
        "  gloss.append(g_loss)\n",
        "\n",
        "  if epoch % sample_interval == 0:\n",
        "    print (\"%d [C loss: %f, acc.: %.2f%%] [G loss: %f]\" % \n",
        "           (epoch, c_loss[0], 100*c_loss[1], g_loss))\n",
        "  \n",
        "    noise = np.random.uniform(0, 1, (2, ltnt_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    samp_imgs[epoch] = gen_imgs"
      ],
      "metadata": {
        "id": "FXjYwaLVDbyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf55e66-be3a-4890-b62c-208984e7100b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [C loss: 0.710588, acc.: 21.88%] [G loss: 0.687957]\n",
            "400 [C loss: 0.000046, acc.: 100.00%] [G loss: 0.000028]\n",
            "800 [C loss: 0.025624, acc.: 99.22%] [G loss: 0.012787]\n",
            "1200 [C loss: 0.711656, acc.: 50.00%] [G loss: 0.392552]\n",
            "1600 [C loss: 0.630438, acc.: 65.62%] [G loss: 0.795434]\n",
            "2000 [C loss: 0.620446, acc.: 63.28%] [G loss: 0.627613]\n",
            "2400 [C loss: 0.597491, acc.: 65.62%] [G loss: 0.933187]\n",
            "2800 [C loss: 0.638771, acc.: 58.59%] [G loss: 0.716047]\n",
            "3200 [C loss: 0.664199, acc.: 55.47%] [G loss: 0.830691]\n",
            "3600 [C loss: 0.669791, acc.: 63.28%] [G loss: 0.789071]\n",
            "4000 [C loss: 0.674077, acc.: 58.59%] [G loss: 0.748519]\n",
            "4400 [C loss: 0.678821, acc.: 60.94%] [G loss: 0.740943]\n",
            "4800 [C loss: 0.685091, acc.: 56.25%] [G loss: 0.740619]\n",
            "5200 [C loss: 0.681371, acc.: 56.25%] [G loss: 0.740327]\n",
            "5600 [C loss: 0.681140, acc.: 57.03%] [G loss: 0.727129]\n",
            "6000 [C loss: 0.691874, acc.: 53.91%] [G loss: 0.713781]\n",
            "6400 [C loss: 0.677927, acc.: 62.50%] [G loss: 0.731661]\n",
            "6800 [C loss: 0.675277, acc.: 60.94%] [G loss: 0.738206]\n",
            "7200 [C loss: 0.668499, acc.: 66.41%] [G loss: 0.749991]\n",
            "7600 [C loss: 0.664848, acc.: 60.94%] [G loss: 0.732330]\n",
            "8000 [C loss: 0.674451, acc.: 55.47%] [G loss: 0.798643]\n",
            "8400 [C loss: 0.673790, acc.: 57.81%] [G loss: 0.767242]\n",
            "8800 [C loss: 0.683633, acc.: 58.59%] [G loss: 0.774512]\n",
            "9200 [C loss: 0.672905, acc.: 56.25%] [G loss: 0.786941]\n",
            "9600 [C loss: 0.685480, acc.: 53.91%] [G loss: 0.785998]\n",
            "10000 [C loss: 0.659129, acc.: 62.50%] [G loss: 0.751011]\n",
            "10400 [C loss: 0.640138, acc.: 71.09%] [G loss: 0.739133]\n",
            "10800 [C loss: 0.671357, acc.: 59.38%] [G loss: 0.876918]\n",
            "11200 [C loss: 0.652008, acc.: 63.28%] [G loss: 0.846699]\n",
            "11600 [C loss: 0.618757, acc.: 68.75%] [G loss: 0.866417]\n",
            "12000 [C loss: 0.643003, acc.: 67.19%] [G loss: 0.830146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above result can  look different in your laptop or computer because this is all based on random noise. This randomness aspect will take your model in a different direction. However,  what you will see is that your generator's loss will decrease dradually and if the generator works properly, the accuracy should be geetting closer to random change, that is close to 50%. If your discriminator is always 100% then your generator is not good enough, and if your dicriminator is around 50% accuracy, then your generator might be too good or discrimitor is too weak."
      ],
      "metadata": {
        "id": "cwC6w6Ivzlpu"
      }
    }
  ]
}